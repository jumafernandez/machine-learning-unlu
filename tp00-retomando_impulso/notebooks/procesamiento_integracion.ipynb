{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9c451d",
   "metadata": {},
   "source": [
    "# Filtrado, preparaci贸n e integraci贸n de datos\n",
    "\n",
    "Esta notebook implementa un pipeline reproducible con **pandas** para:\n",
    "- Renombrar columnas a `snake_case`.\n",
    "- Convertir fechas a `datetime`.\n",
    "- Filtrar viajes de **julio, agosto y septiembre de 2024**.\n",
    "- Guardar un resultado intermedio en `data/interim/recorridos_3meses.csv`.\n",
    "- Verificar la **clave de uni贸n** (`id_usuario` o equivalente) en ambos datasets.\n",
    "- Realizar el **join** entre `recorridos` filtrados y `usuarios`.\n",
    "- Crear la columna **`duracion_viaje_minutos`**.\n",
    "- Guardar el resultado final en `data/processed/recorridos_usuarios_3meses.csv`.\n",
    "\n",
    ">  *Sigue la estructura: textos explicativos breves antes de cada bloque de c贸digo y comentarios puntuales dentro del c贸digo.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e0120",
   "metadata": {},
   "source": [
    "##  Recomendaciones para el uso de notebooks\n",
    "\n",
    "- Usar celdas de texto (Markdown) para documentar cada parte del proceso.\n",
    "- Utilizar t铆tulos y subt铆tulos (`#`, `##`, `###`) para organizar el contenido.\n",
    "- Explicar brevemente **antes** de cada bloque de c贸digo qu茅 se va a hacer y por qu茅.\n",
    "- Incluir comentarios en el c贸digo solo para **aclaraciones puntuales**, no para repetir lo que ya est谩 en el texto.\n",
    "- Mantener el notebook **limpio y ejecutable de principio a fin**, sin errores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37bbe7",
   "metadata": {},
   "source": [
    "## 1锔 Configuraci贸n\n",
    "\n",
    "Define aqu铆 las rutas de entrada/salida y los nombres de columnas clave.  \n",
    "Ajusta los nombres si tus archivos usan otras etiquetas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d74e7d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entradas:\n",
      "  - /Users/devlaptop/Documents/GitHub/machine-learning-unlu/tp00-retomando_impulso/data/raw/usuarios_ecobici_2024.csv\n",
      "  - /Users/devlaptop/Documents/GitHub/machine-learning-unlu/tp00-retomando_impulso/data/raw/badata_ecobici_recorridos_realizados_2024.csv\n",
      "\n",
      "Salidas:\n",
      "  - /Users/devlaptop/Documents/GitHub/machine-learning-unlu/tp00-retomando_impulso/data/interim/recorridos_3meses.csv\n",
      "  - /Users/devlaptop/Documents/GitHub/machine-learning-unlu/tp00-retomando_impulso/data/processed/recorridos_usuarios_3meses.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Configuraci贸n del proyecto ---\n",
    "from pathlib import Path\n",
    "\n",
    "# Directorio ra铆z del proyecto\n",
    "DIRECTORIO = '/Users/devlaptop//Documents/GitHub/machine-learning-unlu/tp00-retomando_impulso/'\n",
    "\n",
    "# Rutas relativas al ra铆z del proyecto (ajusta si es necesario)\n",
    "DATA_RAW = Path(DIRECTORIO + 'data/raw')\n",
    "DATA_INTERIM = Path(DIRECTORIO + 'data/interim')\n",
    "DATA_PROCESSED = Path(DIRECTORIO + 'data/processed')\n",
    "\n",
    "# Nombres de archivos de entrada (ajusta si difieren)\n",
    "F_USUARIOS = DATA_RAW / 'usuarios_ecobici_2024.csv'\n",
    "F_RECORRIDOS = DATA_RAW / 'badata_ecobici_recorridos_realizados_2024.csv'\n",
    "\n",
    "# Salidas\n",
    "F_RECORRIDOS_FILTRADOS = DATA_INTERIM / 'recorridos_3meses.csv'\n",
    "F_FINAL = DATA_PROCESSED / 'recorridos_usuarios_3meses.csv'\n",
    "\n",
    "# Columnas clave (ajusta si difiere)\n",
    "COL_ID_USUARIO = 'id_usuario'               # clave para el join\n",
    "COL_DT_INICIO = 'fecha_origen_recorrido'    # datetime de inicio del viaje\n",
    "COL_DT_FIN = 'fecha_destino_recorrido'      # datetime de fin del viaje\n",
    "\n",
    "# Crear carpetas de salida si no existen\n",
    "for p in [DATA_INTERIM, DATA_PROCESSED]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Entradas:')\n",
    "print('  -', F_USUARIOS)\n",
    "print('  -', F_RECORRIDOS)\n",
    "print('\\nSalidas:')\n",
    "print('  -', F_RECORRIDOS_FILTRADOS)\n",
    "print('  -', F_FINAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900f83e",
   "metadata": {},
   "source": [
    "## 2锔 Carga de datos\n",
    "\n",
    "Leemos los dos CSV desde `data/raw/`. Si tus archivos est谩n en otro formato o nombre, ajusta la configuraci贸n previa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39d9395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usuarios: (197077, 5)\n",
      "recorridos: (3559284, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "usuarios = pd.read_csv(F_USUARIOS)\n",
    "recorridos = pd.read_csv(F_RECORRIDOS)\n",
    "\n",
    "print('usuarios:', usuarios.shape)\n",
    "print('recorridos:', recorridos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a595970",
   "metadata": {},
   "source": [
    "## 3锔 Estandarizaci贸n de nombres a `snake_case`\n",
    "\n",
    "Unificamos el estilo de columnas para evitar errores en merges o referencias posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e234133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas usuarios: ['id_usuario', 'genero_usuario', 'edad_usuario', 'fecha_alta', 'hora_alta']\n",
      "Columnas recorridos: ['id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido', 'id_estacion_origen', 'nombre_estacion_origen', 'direccion_estacion_origen', 'long_estacion_origen', 'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino', 'nombre_estacion_destino', 'direccion_estacion_destino', 'long_estacion_destino', 'lat_estacion_destino', 'id_usuario', 'modelo_bicicleta', 'genero']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def to_snake(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[\\s\\-\\/]+', '_', s)            # espacios y separadores a gui贸n bajo\n",
    "    s = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', s)  # camelCase/PascalCase a snake\n",
    "    s = re.sub(r'__+', '_', s)                  # colapsar dobles guiones bajos\n",
    "    s = re.sub(r'[^a-zA-Z0-9_]', '', s)         # quitar caracteres no v谩lidos\n",
    "    return s.lower()\n",
    "\n",
    "def snakecase_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [to_snake(c) for c in df.columns]\n",
    "    return df\n",
    "\n",
    "usuarios = snakecase_columns(usuarios)\n",
    "recorridos = snakecase_columns(recorridos)\n",
    "\n",
    "print('Columnas usuarios:', usuarios.columns.tolist())\n",
    "print('Columnas recorridos:', recorridos.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181b208",
   "metadata": {},
   "source": [
    "## 4锔 Conversi贸n de fechas a `datetime`\n",
    "\n",
    "Convertimos las columnas de fecha/hora definidas en la configuraci贸n.  \n",
    "Si tus nombres reales difieren, actual铆zalos arriba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99b5e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_origen_recorrido     datetime64[ns]\n",
      "fecha_destino_recorrido    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in [COL_DT_INICIO, COL_DT_FIN]:\n",
    "    if col in recorridos.columns:\n",
    "        recorridos[col] = pd.to_datetime(recorridos[col], errors='coerce', utc=False)\n",
    "    else:\n",
    "        raise KeyError(f'No se encontr贸 la columna de fecha/hora: {col}')\n",
    "\n",
    "# Diagn贸stico r谩pido\n",
    "print(recorridos[[COL_DT_INICIO, COL_DT_FIN]].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381fe21",
   "metadata": {},
   "source": [
    "## 5锔 Filtro de viajes (julioseptiembre 2024)\n",
    "\n",
    "Nos quedamos con recorridos cuyo **inicio** est茅 entre el **1 de julio** y el **30 de septiembre de 2024**.\n",
    "Luego persistimos el resultado intermedio en `data/interim/recorridos_3meses.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84614679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrados: (831984, 17)\n",
      "Guardado intermedio -> /Users/devlaptop/Documents/GitHub/machine-learning-unlu/tp00-retomando_impulso/data/interim/recorridos_3meses.csv\n"
     ]
    }
   ],
   "source": [
    "inicio = pd.Timestamp('2024-07-01 00:00:00')\n",
    "fin = pd.Timestamp('2024-09-30 23:59:59')\n",
    "\n",
    "mask = (recorridos[COL_DT_INICIO] >= inicio) & (recorridos[COL_DT_INICIO] <= fin)\n",
    "recorridos_filtrados = recorridos.loc[mask].copy()\n",
    "\n",
    "print('Filtrados:', recorridos_filtrados.shape)\n",
    "recorridos_filtrados.to_csv(F_RECORRIDOS_FILTRADOS, index=False)\n",
    "print('Guardado intermedio ->', F_RECORRIDOS_FILTRADOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64433099",
   "metadata": {},
   "source": [
    "## 6锔 Verificaci贸n de la clave de uni贸n\n",
    "\n",
    "Comprobamos que la clave (`id_usuario` o equivalente) exista en ambos datasets y revisamos:\n",
    "- **Valores nulos** en la clave.\n",
    "- **Duplicados** (unicidad) en `usuarios` para la clave.\n",
    "- **Coverage**: cu谩ntos `id_usuario` de `recorridos_filtrados` est谩n presentes en `usuarios`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c715094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos en clave:\n",
      "  usuarios: 0\n",
      "  recorridos_filtrados: 0\n",
      "Duplicados de clave en usuarios: 0\n",
      "Coverage de id_usuario (recorridos en usuarios): 45.05%  (47703/105884)\n"
     ]
    }
   ],
   "source": [
    "# Existencia de la clave\n",
    "for df_name, df in [('usuarios', usuarios), ('recorridos_filtrados', recorridos_filtrados)]:\n",
    "    if COL_ID_USUARIO not in df.columns:\n",
    "        raise KeyError(f'No se encontr贸 {COL_ID_USUARIO} en {df_name}')\n",
    "\n",
    "# Nulos\n",
    "print('Nulos en clave:')\n",
    "print('  usuarios:', usuarios[COL_ID_USUARIO].isna().sum())\n",
    "print('  recorridos_filtrados:', recorridos_filtrados[COL_ID_USUARIO].isna().sum())\n",
    "\n",
    "# Duplicados en la tabla de dimensi贸n (usuarios)\n",
    "dups = usuarios[COL_ID_USUARIO].duplicated().sum()\n",
    "print('Duplicados de clave en usuarios:', dups)\n",
    "\n",
    "# Cobertura\n",
    "ids_rec = set(recorridos_filtrados[COL_ID_USUARIO].dropna().unique())\n",
    "ids_usu = set(usuarios[COL_ID_USUARIO].dropna().unique())\n",
    "coverage = len(ids_rec & ids_usu) / max(1, len(ids_rec))\n",
    "print(f'Coverage de id_usuario (recorridos en usuarios): {coverage:.2%}  ({len(ids_rec & ids_usu)}/{len(ids_rec)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a4674",
   "metadata": {},
   "source": [
    "## 7锔 Integraci贸n (join)\n",
    "\n",
    "Hacemos un **left join** de `recorridos_filtrados` con `usuarios` por la clave.  \n",
    "As铆 mantenemos todos los recorridos y anexamos atributos del usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7526b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrado: (831984, 21)\n",
      "Columnas a帽adidas de usuarios: ['genero_usuario', 'edad_usuario', 'fecha_alta', 'hora_alta']\n"
     ]
    }
   ],
   "source": [
    "cols_usuarios = [c for c in usuarios.columns if c != COL_ID_USUARIO]\n",
    "df_integrado = recorridos_filtrados.merge(usuarios, on=COL_ID_USUARIO, how='left', validate='m:1')\n",
    "\n",
    "print('Integrado:', df_integrado.shape)\n",
    "print('Columnas a帽adidas de usuarios:', [c for c in cols_usuarios if c in df_integrado.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64de8f0",
   "metadata": {},
   "source": [
    "## 8锔 Columna derivada `duracion_viaje_minutos`\n",
    "\n",
    "Calculamos la duraci贸n en minutos como la diferencia entre `fecha_fin` y `fecha_inicio`.  \n",
    "Si falta alguno de los extremos o la resta no es v谩lida, el resultado ser谩 `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c083a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripci贸n de duracion_viaje_minutos:\n",
      "count    831984.000000\n",
      "mean         21.408908\n",
      "std         190.600092\n",
      "min           0.000000\n",
      "25%           7.850000\n",
      "50%          14.133333\n",
      "75%          23.766667\n",
      "max       42852.750000\n",
      "Name: duracion_viaje_minutos, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if COL_DT_INICIO not in df_integrado.columns or COL_DT_FIN not in df_integrado.columns:\n",
    "    raise KeyError('No se encuentran las columnas de fecha de inicio/fin en el DF integrado.')\n",
    "\n",
    "dur = (df_integrado[COL_DT_FIN] - df_integrado[COL_DT_INICIO]).dt.total_seconds() / 60.0\n",
    "df_integrado['duracion_viaje_minutos'] = dur.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print('Descripci贸n de duracion_viaje_minutos:')\n",
    "print(df_integrado['duracion_viaje_minutos'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae00cb8",
   "metadata": {},
   "source": [
    "## 9锔 Guardado del resultado final\n",
    "\n",
    "Persistimos el dataset enriquecido en `data/processed/recorridos_usuarios_3meses.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ccc224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado final -> /Users/devlaptop/Documents/GitHub/machine-learning-unlu/tp00-retomando_impulso/data/processed/recorridos_usuarios_3meses.csv\n"
     ]
    }
   ],
   "source": [
    "df_integrado.to_csv(F_FINAL, index=False)\n",
    "print('Guardado final ->', F_FINAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef488395",
   "metadata": {},
   "source": [
    "##  Resumen y chequeos finales\n",
    "\n",
    "Mostramos un resumen r谩pido para verificar el pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66cce4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas finales: 831984\n",
      "Columnas finales: 22\n",
      "\n",
      "Top 10 columnas con m谩s nulos:\n",
      "hora_alta               540976\n",
      "fecha_alta              540976\n",
      "edad_usuario            540976\n",
      "genero_usuario          540976\n",
      "genero                    2907\n",
      "id_recorrido                 0\n",
      "duracion_recorrido           0\n",
      "modelo_bicicleta             0\n",
      "id_usuario                   0\n",
      "lat_estacion_destino         0\n",
      "dtype: int64\n",
      "\n",
      "Tipos de datos (primeras 20 columnas):\n",
      "id_recorrido                           int64\n",
      "duracion_recorrido                     int64\n",
      "fecha_origen_recorrido        datetime64[ns]\n",
      "id_estacion_origen                     int64\n",
      "nombre_estacion_origen                object\n",
      "direccion_estacion_origen             object\n",
      "long_estacion_origen                 float64\n",
      "lat_estacion_origen                  float64\n",
      "fecha_destino_recorrido       datetime64[ns]\n",
      "id_estacion_destino                    int64\n",
      "nombre_estacion_destino               object\n",
      "direccion_estacion_destino            object\n",
      "long_estacion_destino                float64\n",
      "lat_estacion_destino                 float64\n",
      "id_usuario                             Int64\n",
      "modelo_bicicleta                      object\n",
      "genero                                object\n",
      "genero_usuario                        object\n",
      "edad_usuario                         float64\n",
      "fecha_alta                            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Filas finales:', df_integrado.shape[0])\n",
    "print('Columnas finales:', df_integrado.shape[1])\n",
    "\n",
    "# Nulos por columna (top 10)\n",
    "nulos = df_integrado.isnull().sum().sort_values(ascending=False).head(10)\n",
    "print('\\nTop 10 columnas con m谩s nulos:')\n",
    "print(nulos)\n",
    "\n",
    "print('\\nTipos de datos (primeras 20 columnas):')\n",
    "print(df_integrado.dtypes.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
